{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Challenge LATAM AIRLINES Data Engineer**\n",
    "\n",
    "For this challenge a data has been given, the data is about tweets from Twitter, it comes as a JSON file wich has a size of 389Mb aprox. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we have to set the file into a place it can be accessed and not in the repository, by being a large file. \n",
    "\n",
    "I uploaded it to `Google Cloud Storage`, inside a `bucket`. From here we'll refer to `Google Cloud Storage` as `GCS`.\n",
    "\n",
    "The files at `GCS` has a path like `\"gs://{bucket_name}/{blob.name}\"`. Bucket name and file is reserved by me in my `GCS` and `env file`.\n",
    "\n",
    "I created a `.env` file where i set my enviroment variables as\n",
    "- `PROJECT_ID`: The Google Cloud Platform (`GCP`) project where the bucket of `GCS` is allowed.\n",
    "- `BUCKET_NAME`: The name of the `GCS` bucket\n",
    "- `GCP_CREDENTIALS`: The Json content of the key to the service account in `GCP` to log into `Google Cloud`.\n",
    "- `BUCKET_FOLDER_ORIGIN`: The folder inside the bucket where data is stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added a python file named `json_to_dataframe.py` where i make the connection to `GCS`. \n",
    "\n",
    "This file has modules to get the file path and get a dataframe from the given file.\n",
    "\n",
    "So, now that my environment is set `I can start to code!`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we will get the file path from our `cloud bucket`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in to GCP / GCS client\n",
      "BLOBS LISTED! ----------------------\n",
      "[<Blob: latam-airlines, Data/, 1710462726242408>, <Blob: latam-airlines, Data/farmers-protest-tweets.json, 1710465820905781>]\n",
      "The file name is \n",
      "The file name is farmers-protest-tweets.json\n",
      "BUILDING FILE PATH! ----------------------\n"
     ]
    }
   ],
   "source": [
    "import json_to_dataframe as jtd \n",
    "import os\n",
    "import pandas as pd\n",
    "import cProfile\n",
    "import pstats\n",
    "from memory_profiler import profile\n",
    "\n",
    "file_path = jtd.get_gcs_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the file path, we can download the file to work it offline. \n",
    "\n",
    "First we call from jtd the method download file, this method downloads the file into folder `src/files/`. If the file already exist in the folder, it doesn't get downloaded. The method returns the local path of the json file.\n",
    "\n",
    "With the file downloaded, the local path file is used to read the file with `pandas` and save it to parquet format (best by compression of large data) if the parquet file doesn't exist.\n",
    "\n",
    "Finally, build the parquet file path in local and save it in a variable.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = os.path.join(os.path.dirname(os.path.abspath(\"q1_memory.py\")), \"files\")\n",
    "local_json_file_path = jtd.download_file(file_path,directory_path)\n",
    "df= pd.read_json(local_json_file_path, lines=True)\n",
    "# Get the file name from the file path\n",
    "file_name = os.path.basename(local_json_file_path)\n",
    "# parquet file name\n",
    "parquet_file_name = file_name.split('.')[0] + '.parquet'\n",
    "# If parquet file does not exist, create a new parquet file\n",
    "if not os.path.exists(os.path.join(directory_path, parquet_file_name)):\n",
    "    df.to_parquet(os.path.join(directory_path, parquet_file_name),engine='auto')\n",
    "    print(\"Parquet file created\")\n",
    "# Get the path of the parquet file\n",
    "parquet_file_local_path = os.path.join(directory_path, parquet_file_name)\n",
    "# Clear df from memory\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All questions receive as parameters a file_path and have two approaches, one **based on time** and the other one **based on memory**.\n",
    "\n",
    "The time based approaches are optimal with the parquet files, by that reason we will pass as path parameter the parquet file path.\n",
    "\n",
    "\n",
    "\n",
    "A better way to make better this comparison and questions is by using a ***database or data warehouse***, to execute querys. Personally, I use ***BigQuery*** because it computes querys in large remote cluster servers at the same time, which makes the time response short by dividing one Query in multiple sub-queries, optimizing memory and time at the same time. And can be consumed by reporting tools by connecting to data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Question/Challenge 1***\n",
    "\n",
    "\"Las top 10 fechas donde hay más tweets. Mencionar el usuario (username) que más publicaciones tiene por cada uno de esos días.\"\n",
    "\n",
    "Top 10 dates where there are the most tweets. Mention the user (username) who has the most publications for each of those days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For consulting this, we have to read the data from the file in json/parquet. \n",
    "#### **Time Approach**\n",
    "I used pandas as my reader/interpreter, it returns a dataframe from the parquet file previously built.\n",
    "\n",
    "In this module we read the parquet file using the pandas functionality .read_parquet, otherwise, i enabled the method the possibility to read json file if json file is passed as parameter.\n",
    "```python\n",
    "if file_path.endswith(\".json\"):\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "elif file_path.endswith(\".parquet\"):\n",
    "    df = pd.read_parquet(file_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach use pandas as the reader, it reads all the file and keep it as a dataframe in memory. That makes it better for time of response to the consult, but makes data is always loaded at memory.\n",
    "\n",
    "At first, convert the date column from datetime to format date. Takes username from user as the user.\n",
    "\n",
    "Use `.value_counts()` to count over date field of dataframe, counts all ocurrences in the field and order it from bigger to smaller, we take the first 10 with `.head(10)`\n",
    "```python\n",
    "top_10_dates = df[\"date\"].value_counts().head(10)\n",
    "```\n",
    "\n",
    "Now we have to get the user with more tweets (rows or count) on each date, by iterating on each date and using date as dataframe filter, where the user field is used in value_counts to make a count by user on the specific day. After that, take `idxmax()` to get the first row, also can be used `.head(1)`, this takes the user with most tweets. User and date are append to the python list `result`. Result returns the 10 dates with the user with most tweets in each date.\n",
    "\n",
    "```python\n",
    "result = []\n",
    "# Iterate over the top 10 dates\n",
    "for date in top_10_dates.index:\n",
    "    # Get the user with the most tweets in the date\n",
    "    user = df[df[\"date\"] == date][\"user\"].value_counts().idxmax()\n",
    "    # Append the date and the user to the result list\n",
    "    result.append((date, user))\n",
    "```\n",
    "\n",
    "The full code of this approach is at \n",
    "[q1_time.py](https://github.com/JoRgEXx1899/latam-de-challenge/blob/main/src/q1_time.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1_time.py executed successfully\n",
      "Results:\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n"
     ]
    }
   ],
   "source": [
    "from q1_time import q1_time\n",
    "\n",
    "q1_t_result = q1_time(parquet_file_local_path)\n",
    "print(\"q1_time.py executed successfully\")\n",
    "print(\"Results:\")\n",
    "print(q1_t_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Memory Approach**\n",
    "\n",
    "For this approach pandas is not used as the reader, because we have to optimize the memory use. Pandas, as i explained before, keeps data on memory which makes it not optimal for a memory optimizing approach. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach iterates line by line of the JSON file, ensuring one line at time in memory.\n",
    "\n",
    "Why not to use the parquet file? Because parquet file is focused on making better execution accros the time, but not memory.\n",
    "\n",
    "Uses a dictionary to store by date the user count. Line by line gets the date and user of the tweet and adds +1 to the count of the user in the date.\n",
    "\n",
    "With the dictionary built, just have to get the top user by date, then append date and top user into a list. The list is sorted according with most date count from major to minor. We slice the first 10 lines of the list and return it as the result. The full code of this approach is at [q1_memory.py](https://github.com/JoRgEXx1899/latam-de-challenge/blob/main/src/q1_memory.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1_memory.py executed successfully\n",
      "Results:\n",
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 19), 'Preetm91'), (datetime.date(2021, 2, 21), 'Surrypuria'), (datetime.date(2021, 2, 23), 'Surrypuria')]\n"
     ]
    }
   ],
   "source": [
    "from q1_memory import q1_memory\n",
    "\n",
    "q1_m_result = q1_memory(local_json_file_path)\n",
    "print(\"q1_memory.py executed successfully\")\n",
    "print(\"Results:\")\n",
    "print(q1_m_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the result and code. Make some measures about both approaches. At first we evaluate memory approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Evaluation q1_time\n",
      "\n",
      "peak memory: 1680.67 MiB, increment: 842.67 MiB\n",
      "\n",
      "Evaluación de memoria q1_memory\n",
      "\n",
      "Memory Evaluation q1_memory\n",
      "\n",
      "peak memory: 1214.61 MiB, increment: 1.45 MiB\n"
     ]
    }
   ],
   "source": [
    "# Load the memory_profiler extension to evaluate the memory usage in the functions\n",
    "%load_ext memory_profiler\n",
    "%reload_ext memory_profiler\n",
    "\n",
    "# Evaluates the memory usage of the q1_time function\n",
    "print(\"Memory Evaluation q1_time\\n\")\n",
    "%memit q1_time(parquet_file_local_path)\n",
    "\n",
    "# Evaluates the memory usage of the q1_memory function\n",
    "print(\"\\nEvaluación de memoria q1_memory\\n\")\n",
    "print(\"Memory Evaluation q1_memory\\n\")\n",
    "%memit q1_memory(local_json_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the memory used by q1_memory is smaller than the memory used by the q1_time approach.\n",
    "\n",
    "Now the turn for time approach. First we evaluate `q1_time` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 15 16:54:52 2024    output.pstats1\n",
      "\n",
      "         134714 function calls (134391 primitive calls) in 2.031 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 617 to 2 due to restriction <2>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.003    0.003    2.031    2.031 c:\\Users\\danie\\OneDrive\\Documents\\GitHub\\latam-de-challenge\\src\\q1_time.py:7(q1_time)\n",
      "        1    0.001    0.001    1.912    1.912 c:\\Users\\danie\\.conda\\envs\\latamair\\Lib\\site-packages\\pandas\\io\\parquet.py:428(read_parquet)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x27696de4390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the profiler\n",
    "profiler = cProfile.Profile()\n",
    "# Run the profiler for q1_time function\n",
    "profiler.runcall(q1_time, parquet_file_local_path)\n",
    "# Print the statistics of the profiler\n",
    "# Get the total time spent in the function\n",
    "#profiler.print_stats(sort='cumtime')\n",
    "# Disable the cProfile profiler and save statistics to a file\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats1\")\n",
    "# Create an instance of pstats Stats to analyze the statistics\n",
    "stats = pstats.Stats(\"output.pstats1\")\n",
    "# Sort the statistics by the time spent in the function\n",
    "stats.sort_stats(\"cumtime\")\n",
    "# Print the statistics\n",
    "stats.print_stats(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now evaluate `q1_memory` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 15 17:15:03 2024    output.pstats1\n",
      "\n",
      "         9943523 function calls (9943200 primitive calls) in 15.903 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 642 to 2 due to restriction <2>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        3    2.949    0.983   13.872    4.624 c:\\Users\\danie\\OneDrive\\Documents\\GitHub\\latam-de-challenge\\src\\q1_memory.py:7(q1_memory)\n",
      "   352221    5.709    0.000    5.709    0.000 {built-in method ujson.loads}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the profiler for q1_time function\n",
    "profiler.runcall(q1_memory, local_json_file_path)\n",
    "# Print the statistics of the profiler\n",
    "# Get the total time spent in the function\n",
    "#profiler.print_stats(sort='cumtime')\n",
    "# Disable the cProfile profiler and save statistics to a file\n",
    "profiler.disable()\n",
    "profiler.dump_stats(\"output.pstats1\")\n",
    "# Create an instance of pstats Stats to analyze the statistics\n",
    "stats = pstats.Stats(\"output.pstats1\")\n",
    "# Sort the statistics by the time spent in the function\n",
    "stats.sort_stats(\"cumtime\")\n",
    "# Print the statistics\n",
    "stats.print_stats(2)\n",
    "\n",
    "# Remove the pstats file\n",
    "os.remove(\"output.pstats1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As wee can see, the `q1_time` function is better in execution time than `q1_memory` function."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
